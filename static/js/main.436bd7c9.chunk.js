(this.webpackJsonptransmute=this.webpackJsonptransmute||[]).push([[0],{75:function(e,t,a){},89:function(e,t,a){"use strict";a.r(t);var n=a(1),i=a.n(n),r=a(10),s=a.n(r),c=(a(75),a(49)),o=a(30),l=a(66),d=a(65),h=a(31),j=a(9),m=a(121),b=a(123),p=a(0),g=Object(m.a)((function(e){return{root:{width:"100%",padding:"2%",height:"auto"},column:{width:"90%",marginLeft:"5%",marginRight:"5%",paddingTop:"5%"},float:{float:"left",width:"31%",marginLeft:"1%"},paragraph:{width:"90%",marginLeft:"5%",marginRight:"5%",height:"auto",fontFamily:"Sans-serif",fontSize:"22px"},heading:{fontFamily:"Serif",color:"#1ca9c9",width:"40%",marginLeft:"35%"},boxheading:{fontFamily:"Serif",color:"#002147"},boxparagraph:{fontFamily:"Sans-serif",color:"#002147"},mediaParagraph:{width:"84%",marginLeft:"6%",marginRight:"6%",height:"auto",fontFamily:"Sans-serif",fontSize:"18px"},mediaHeading:{fontFamily:"Serif",color:"#1ca9c9",width:"80%",marginLeft:"6%",marginRight:"6%"}}}));function u(){var e=g(),t=Object(b.a)("(min-width:800px)");return Object(p.jsx)("div",{children:t?Object(p.jsxs)("div",{className:e.root,children:[Object(p.jsx)("h3",{className:e.heading,children:"Transmute AI Lab"}),Object(p.jsx)("p",{className:e.paragraph,children:"A network of self-driven researchers passionate about experiencing new reality with Artificial Intelligence (AI). We envision breakthroughs in AI and are thriving to build cutting-edge AI technologies that will revolutionize the world."}),Object(p.jsxs)("div",{className:e.column,children:[Object(p.jsxs)("div",{className:e.float,children:[Object(p.jsx)("h5",{className:e.boxheading,children:"Who are we?"}),Object(p.jsx)("p",{className:e.boxparagraph,children:"We are a group of experienced researchers and young students who are passionate about contributing towards AI research. We enjoy working on AI research problems, and we do it for fun. We are a virtual research lab with members spread across the globe, but we know how to connect and collaborate. Stay tuned for more updates."})]}),Object(p.jsxs)("div",{className:e.float,children:[Object(p.jsx)("h5",{className:e.boxheading,children:"What do we do?"}),Object(p.jsx)("p",{className:e.boxparagraph,children:"Our experienced researchers come up with great AI ideas. They mentor the young students and get them onboard with the required background knowledge of the problems. While the students actively work on the project, they receive close mentorship. Together, we come up with an awesome solution to the problem and present it to the scientific community."})]}),Object(p.jsxs)("div",{className:e.float,children:[Object(p.jsx)("h5",{className:e.boxheading,children:"Why do we do it?"}),Object(p.jsx)("p",{className:e.boxparagraph,children:"We do it because we enjoy working together. It helps the young students with the exposure and experience needed for the top higher education universities in AI as well as the competitive job market. Our senior researchers enjoy the mentorship and engagement of the students. Together, all of us enjoy seeing our work making a difference in the AI community."})]})]})]}):Object(p.jsxs)("div",{className:e.root,children:[Object(p.jsx)("h3",{className:e.mediaHeading,children:"Transmute AI Lab"}),Object(p.jsx)("p",{className:e.mediaParagraph,children:"A network of self-driven researchers passionate about experiencing new reality with Artificial Intelligence (AI). We envision breakthroughs in AI and are thriving to build cutting-edge AI technologies that will revolutionize the world."}),Object(p.jsxs)("div",{children:[Object(p.jsx)("h4",{className:e.mediaHeading,children:"Who are we?"}),Object(p.jsx)("p",{className:e.mediaParagraph,children:"We are a group of experienced researchers and young students who are passionate about contributing towards AI research. We enjoy working on AI research problems, and we do it for fun. We are a virtual research lab with members spread across the globe, but we know how to connect and collaborate. Stay tuned for more updates."})]}),Object(p.jsxs)("div",{children:[Object(p.jsx)("h4",{className:e.mediaHeading,children:"What do we do?"}),Object(p.jsx)("p",{className:e.mediaParagraph,children:"Our experienced researchers come up with great AI ideas. They mentor the young students and get them onboard with the required background knowledge of the problems. While the students actively work on the project, they receive close mentorship. Together, we come up with an awesome solution to the problem and present it to the scientific community."})]}),Object(p.jsxs)("div",{children:[Object(p.jsx)("h4",{className:e.mediaHeading,children:"Why do we do it?"}),Object(p.jsx)("p",{className:e.mediaParagraph,children:"We do it because we enjoy working together. It helps the young students with the exposure and experience needed for the top higher education universities in AI as well as the competitive job market. Our senior researchers enjoy the mentorship and engagement of the students. Together, all of us enjoy seeing our work making a difference in the AI community."})]})]})})}var f=a(3),O=a(56),x=a(38),w=a(58),v=a.n(w),k=(a(79),a(128)),N=a(129),y=a(53),I=a(93),S=a(130),T=a(64),C=a.n(T),A=a(124),L=a(125),F=a(126),z=a(127),D=a(5),M=a(132),B=Object(m.a)((function(e){return{root:{flexGrow:1},menuButton:{marginRight:e.spacing(1)},menuIcon:{fontSize:"40px"},title:{flexGrow:1},youtube:{color:"white",fontSize:"25px"},navbar:{backgroundColor:"#002147",paddingRight:"1%",paddingLeft:"1%"},list:{width:250},fullList:{width:"auto"},sideBarFont:{fontFamily:"Sans-serif",color:"#002147",fontSize:"18px"},sideBarLogo:{color:"#002147"}}}));function P(){var e,t=B(),a=Object(j.f)(),n=Object(b.a)("(min-width:800px)"),r=i.a.useState({left:!1,right:!1,top:!1,bottom:!1}),s=Object(x.a)(r,2),c=s[0],o=s[1],l=function(e,t){return function(a){("keydown"!==a.type||"Tab"!==a.key&&"Shift"!==a.key)&&o(Object(O.a)(Object(O.a)({},c),{},Object(f.a)({},e,t)))}};return Object(p.jsx)("div",{children:n?Object(p.jsx)("div",{className:t.root,children:Object(p.jsx)(k.a,{position:"static",className:t.navbar,children:Object(p.jsxs)(N.a,{children:[Object(p.jsx)(y.a,{variant:"h6",className:t.title,children:"Transmute AI"}),Object(p.jsx)(I.a,{color:"inherit",onClick:function(){return a.push("/TransmuteAI")},children:"Home"}),Object(p.jsx)(I.a,{color:"inherit",children:"Projects"}),Object(p.jsx)(I.a,{color:"inherit",children:"Members"}),Object(p.jsx)(I.a,{color:"inherit",children:"Courses"}),Object(p.jsx)(I.a,{color:"inherit",onClick:function(){return a.push("/TransmuteAI/publications")},children:"Publications"}),Object(p.jsx)(I.a,{color:"inherit",onClick:function(){return a.push("/TransmuteAI/joinus")},children:"Join us"}),Object(p.jsx)("a",{href:"https://www.youtube.com/channel/UCSBllKwExVPNLDrK1Ujexkw",target:"_blank",rel:"noreferrer",children:Object(p.jsx)(v.a,{className:t.youtube})})]})})}):Object(p.jsx)("div",{children:Object(p.jsx)(k.a,{position:"static",className:t.navbar,children:Object(p.jsxs)(N.a,{children:[Object(p.jsx)(S.a,{edge:"start",className:t.menuButton,color:"inherit","aria-label":"menu",children:Object(p.jsx)("div",{children:Object(p.jsxs)(i.a.Fragment,{children:[Object(p.jsx)(C.a,{onClick:l("top",!0),className:t.menuIcon}),Object(p.jsx)(M.a,{anchor:"top",open:c.top,onClose:l("top",!1),children:(e="top",Object(p.jsx)("div",{className:Object(D.a)(t.list,Object(f.a)({},t.fullList,"top"===e||"bottom"===e)),role:"presentation",onClick:l(e,!1),onKeyDown:l(e,!1),children:Object(p.jsxs)(A.a,{children:[Object(p.jsxs)(L.a,{children:[Object(p.jsx)(F.a,{}),Object(p.jsx)(z.a,{onClick:function(){return a.push("/TransmuteAI")},children:Object(p.jsx)("div",{className:t.sideBarFont,children:"Home"})})]}),Object(p.jsxs)(L.a,{children:[Object(p.jsx)(F.a,{}),Object(p.jsx)(z.a,{children:Object(p.jsx)("div",{className:t.sideBarFont,children:"Projects"})})]}),Object(p.jsxs)(L.a,{children:[Object(p.jsx)(F.a,{}),Object(p.jsx)(z.a,{children:Object(p.jsx)("div",{className:t.sideBarFont,children:"Members"})})]}),Object(p.jsxs)(L.a,{children:[Object(p.jsx)(F.a,{}),Object(p.jsx)(z.a,{children:Object(p.jsx)("div",{className:t.sideBarFont,children:"Courses"})})]}),Object(p.jsxs)(L.a,{children:[Object(p.jsx)(F.a,{}),Object(p.jsx)(z.a,{onClick:function(){return a.push("/TransmuteAI/publications")},children:Object(p.jsx)("div",{className:t.sideBarFont,children:"Publications"})})]}),Object(p.jsxs)(L.a,{children:[Object(p.jsx)(F.a,{}),Object(p.jsx)(z.a,{onClick:function(){return a.push("/TransmuteAI/joinus")},children:Object(p.jsx)("div",{className:t.sideBarFont,children:"Join Us"})})]})]})}))})]},"top")})}),Object(p.jsx)(y.a,{variant:"h6",className:t.title,children:"Transmute AI"}),Object(p.jsx)("a",{href:"https://www.youtube.com/channel/UCSBllKwExVPNLDrK1Ujexkw",target:"_blank",rel:"noreferrer",children:Object(p.jsx)(v.a,{className:t.youtube})})]})})})})}var R=Object(m.a)((function(e){return{root:{width:"100%"},heading:{width:"80%",marginLeft:"10%",fontFamily:"Serif",color:"#002147"},paragraph:{width:"80%",marginLeft:"10%",fontFamily:"Serif",fontSize:"20px"},student:{fontFamily:"Serif",color:"#002147",fontSize:"28px",marginLeft:"10%",marginBottom:"-25px"},paragraphs:{width:"80%",marginLeft:"10%",fontFamily:"Serif",fontSize:"18px"},students:{fontFamily:"Serif",color:"#002147",fontSize:"22px",marginLeft:"10%",marginBottom:"-15px"}}}));function U(){var e=R(),t=Object(b.a)("(min-width:800px)");return Object(p.jsx)("div",{className:e.root,children:t?Object(p.jsxs)("div",{children:[Object(p.jsx)("div",{className:e.heading,children:Object(p.jsx)("h3",{children:"Do you have what it takes to be a Transmuter?"})}),Object(p.jsxs)("div",{className:e.paragraph,children:[Object(p.jsx)("p",{children:"We are constantly looking for passionate and self-driven students and researchers who would like to join us on cutting-edge projects. We would like to hear more about you through the form accessible at the button below."}),Object(p.jsx)("p",{children:"Please note that we work in our free time and can only handle very limited members in team. We are currently full, but please feel free to fill the form below. We will get back if a spot opens up in the team and we find you a right match."})]}),Object(p.jsx)("p",{className:e.student,children:"Students"}),Object(p.jsxs)("p",{className:e.paragraph,children:["Use this google"," ",Object(p.jsx)("a",{href:"https://forms.gle/x2gQ1b8ZTU1EteQF6",children:"form"})]}),Object(p.jsx)("p",{className:e.student,children:"Mentors"}),Object(p.jsxs)("p",{className:e.paragraph,children:["Use this google"," ",Object(p.jsx)("a",{href:"https://forms.gle/x2gQ1b8ZTU1EteQF6",children:"form"})]})]}):Object(p.jsxs)("div",{children:[Object(p.jsx)("div",{className:e.heading,children:Object(p.jsx)("h4",{children:"Do you have what it takes to be a Transmuter?"})}),Object(p.jsxs)("div",{className:e.paragraph,children:[Object(p.jsx)("p",{children:"We are constantly looking for passionate and self-driven students and researchers who would like to join us on cutting-edge projects. We would like to hear more about you through the form accessible at the button below."}),Object(p.jsx)("p",{children:"Please note that we work in our free time and can only handle very limited members in team. We are currently full, but please feel free to fill the form below. We will get back if a spot opens up in the team and we find you a right match."})]}),Object(p.jsx)("p",{className:e.students,children:"Students"}),Object(p.jsxs)("p",{className:e.paragraphs,children:["Use this google"," ",Object(p.jsx)("a",{href:"https://forms.gle/x2gQ1b8ZTU1EteQF6",children:"form"})]}),Object(p.jsx)("p",{className:e.students,children:"Mentors"}),Object(p.jsxs)("p",{className:e.paragraphs,children:["Use this google"," ",Object(p.jsx)("a",{href:"https://forms.gle/x2gQ1b8ZTU1EteQF6",children:"form"})]})]})})}var W=a(131);function _(){var e=E(),t=Object(j.f)();return Object(p.jsxs)("div",{className:e.root,children:[Object(p.jsx)("h5",{className:e.header,children:"PUBLICATIONS"}),Object(p.jsxs)("div",{className:e.float,children:[Object(p.jsx)("div",{children:Object(p.jsx)("img",{src:"./logo192.png",alt:"Deepak k. gupta"})}),Object(p.jsx)("div",{children:Object(p.jsx)("img",{src:"./logo192.png",alt:"Deepak k. gupta"})}),Object(p.jsx)("div",{children:Object(p.jsx)("img",{src:"./logo192.png",alt:"Deepak k. gupta"})})]}),Object(p.jsxs)("div",{className:e.left,children:[Object(p.jsxs)("div",{children:[Object(p.jsx)("h5",{children:Object(p.jsx)("a",{className:e.heading,href:" ",onClick:function(){return t.push("/TransmuteAI/publications/rescaling")},children:"Rescaling CNN through Learnable Repetition of Network Parameters"})}),Object(p.jsxs)("div",{className:e.width,children:[Object(p.jsx)("h6",{className:e.none,children:Object(p.jsx)("a",{href:" ",onClick:function(){return t.push("/TransmuteAI/publications/arnav")},children:"Arnav Chavan ,"})}),Object(p.jsx)("h6",{className:e.none,children:Object(p.jsx)("a",{href:" ",onClick:function(){return t.push("/TransmuteAI/publications/udbhav")},children:"Udbhav Bamba ,"})}),Object(p.jsx)("h6",{className:e.none,children:Object(p.jsx)("a",{href:" ",onClick:function(){return t.push("/TransmuteAI/publications/rishab")},children:"Rishabh Tiwari ,"})}),Object(p.jsx)("h6",{className:e.none,children:Object(p.jsx)("a",{href:" ",onClick:function(){return t.push("/TransmuteAI/publications/deepak")},children:"Deepak K. Gupta"})})]}),Object(p.jsxs)("div",{className:e.inter,children:[Object(p.jsx)("h6",{className:e.paragraph,children:"International Conference on Image Processing(ICIP)"}),Object(p.jsx)("h6",{className:e.paragraph,children:"May, 2021"})]}),Object(p.jsx)("div",{children:Object(p.jsxs)(W.a,{size:"small","aria-label":"small outlined button group",color:"#002147",children:[Object(p.jsx)(I.a,{className:e.link,onClick:function(){return t.push("/TransmuteAI/publications/rescaling")},children:"Details"}),Object(p.jsx)(I.a,{children:Object(p.jsx)("a",{href:"https://arxiv.org/abs/2101.05650",target:"_blank",rel:"noreferrer",className:e.link,children:"PDF"})}),Object(p.jsx)(I.a,{children:Object(p.jsx)("a",{href:"https://github.com/transmuteAI/RepeatNet/",target:"_blank",rel:"noreferrer",className:e.link,children:"Code"})})]})})]}),Object(p.jsxs)("div",{children:[Object(p.jsx)("h5",{children:Object(p.jsx)("a",{className:e.heading,onClick:function(){return t.push("/TransmuteAI/publications/generating")},href:" ",children:"Generating Annotated High-Fidelity Images containing Multiple Coherent Objects"})}),Object(p.jsxs)("div",{className:e.width,children:[Object(p.jsx)("h6",{className:e.none,children:Object(p.jsx)("a",{href:" ",onClick:function(){return t.push("/TransmuteAI/publications/bryan")},children:"Bryan Cardenas ,"})}),Object(p.jsx)("h6",{className:e.none,children:Object(p.jsx)("a",{href:" ",onClick:function(){return t.push("/TransmuteAI/publications/deepanshu")},children:"devanshu Arya ,"})}),Object(p.jsx)("h6",{className:e.none,children:Object(p.jsx)("a",{href:" ",onClick:function(){return t.push("/TransmuteAI/publications/deepak")},children:"Deepak Kumar Gupta."})})]}),Object(p.jsxs)("div",{className:e.inter,children:[Object(p.jsxs)("h6",{className:e.paragraph,children:["International Conference on Image Processing(ICIP)"," "]}),Object(p.jsx)("h6",{className:e.paragraph,children:"May, 2021"})]}),Object(p.jsx)("div",{children:Object(p.jsxs)(W.a,{size:"small","aria-label":"small outlined button group",color:"#002147",children:[Object(p.jsx)(I.a,{className:e.link,onClick:function(){return t.push("/TransmuteAI/publications/generating")},children:"Details"}),Object(p.jsx)(I.a,{children:Object(p.jsx)("a",{href:"https://arxiv.org/abs/2006.12150",target:"_blank",rel:"noreferrer",className:e.link,children:"PDF"})}),Object(p.jsx)(I.a,{children:Object(p.jsx)("a",{href:"https://github.com/Cynetics/MSGNet/",target:"_blank",rel:"noreferrer",className:e.link,children:"Code"})})]})})]}),Object(p.jsxs)("div",{children:[Object(p.jsx)("h5",{children:Object(p.jsx)("a",{className:e.heading,onClick:function(){return t.push("/TransmuteAI/publications/chipnets")},href:" ",children:"ChipNet: Budget-Aware Pruning with Heaviside Continuous Approximations"})}),Object(p.jsxs)("div",{className:e.width,children:[Object(p.jsx)("h6",{className:e.none,children:Object(p.jsx)("a",{href:" ",onClick:function(){return t.push("/TransmuteAI/publications/rishab")},children:"Rishabh Tiwari ,"})}),Object(p.jsx)("h6",{className:e.none,children:Object(p.jsx)("a",{href:" ",onClick:function(){return t.push("/TransmuteAI/publications/udbhav")},children:"Udbhav Bamba ,"})}),Object(p.jsx)("h6",{className:e.none,children:Object(p.jsx)("a",{href:" ",onClick:function(){return t.push("/TransmuteAI/publications/arnav")},children:"Arnav Chavan ,"})}),Object(p.jsx)("h6",{className:e.none,children:Object(p.jsx)("a",{href:" ",onClick:function(){return t.push("/TransmuteAI/publications/deepak")},children:"Deepak K. Gupta"})})]}),Object(p.jsxs)("div",{className:e.inter,children:[Object(p.jsxs)("h6",{className:e.paragraph,children:["International Conference on Image Processing(ICIP)"," "]}),Object(p.jsx)("h6",{className:e.paragraph,children:"May, 2021"})]}),Object(p.jsx)("div",{children:Object(p.jsxs)(W.a,{size:"small","aria-label":"small outlined button group",color:"#002147",children:[Object(p.jsx)(I.a,{className:e.link,onClick:function(){return t.push("/TransmuteAI/publications/chipnets")},children:"Details"}),Object(p.jsx)(I.a,{children:Object(p.jsx)("a",{href:"https://openreview.net/forum?id=xCxXwTzx4L1",target:"_blank",rel:"noreferrer",className:e.link,children:"PDF"})}),Object(p.jsx)(I.a,{children:Object(p.jsx)("a",{href:"https://github.com/transmuteAI/ChipNet",target:"_blank",rel:"noreferrer",className:e.link,children:"Code"})})]})})]})]})]})}var E=Object(m.a)((function(e){return{root:{width:"100%",padding:"1%"},header:Object(f.a)({fontFamily:"Serif",color:"#1ca9c9",fontSize:"32px"},e.breakpoints.up("sm"),{fontSize:"48px",padding:"1%"}),float:Object(f.a)({display:"none"},e.breakpoints.up("md"),{display:"block",width:"40%",float:"left"}),left:Object(f.a)({width:"100%"},e.breakpoints.up("md"),{width:"60%",float:"left",paddingTop:"2%"}),heading:{fontFamily:"Serif",color:"#1ca9c9"},width:{width:"100%",float:"none",paddingBottom:"1%"},none:Object(f.a)({float:"left",marginTop:"-9px",fontSize:"14px"},e.breakpoints.up("md"),{fontSize:"16px",marginTop:"-11px"}),inter:Object(f.a)({width:"100%",marginTop:"5%"},e.breakpoints.up("md"),{marginTop:"1%",width:"100%"}),button:{marginBottom:"1%"},link:{color:"black"},bottommargin:{marginBottom:"3%"},paragraph:Object(f.a)({fontFamily:"Sans-serif",fontSize:"14px"},e.breakpoints.up("md"),{fontSize:"16px"})}})),K=Object(m.a)((function(e){return{column:Object(f.a)({float:"none",fontFamily:"Sans-serif",color:"#002147"},e.breakpoints.up("sm"),{float:"left",padding:"1%"}),root:Object(f.a)({width:"96%",paddingTop:"1%",marginLeft:"2%",marginRight:"2%"},e.breakpoints.up("md"),{width:"76%",paddingTop:"1%",marginLeft:"12%",marginRight:"12%"}),paragraph:Object(f.a)({fontFamily:"Sans-serif",fontSize:"16px"},e.breakpoints.up("sm"),{fontSize:"18px"}),heading:{fontFamily:"Serif",color:"#002147"},link:{color:"#002147"},width:Object(f.a)({width:"100%",marginBottom:"22%"},e.breakpoints.up("sm"),{width:"90%",marginBottom:"8%"}),widthup:Object(f.a)({width:"100%",marginTop:"22%"},e.breakpoints.up("sm"),{width:"90%",marginTop:"8%"}),float:{float:"left"}}}));function H(){var e=K(),t=Object(j.f)();return Object(p.jsxs)("div",{className:e.root,children:[Object(p.jsx)("h3",{className:e.heading,children:"Rescaling CNN through Learnable Repetition of Network Parameters"}),Object(p.jsxs)("div",{className:e.width,children:[Object(p.jsx)("h6",{className:e.float,children:Object(p.jsx)("a",{href:" ",onClick:function(){return t.push("/TransmuteAI/publications/rishab")},children:"Rishabh Tiwari ,"})}),Object(p.jsx)("h6",{className:e.float,children:Object(p.jsx)("a",{href:" ",onClick:function(){return t.push("/TransmuteAI/publications/udbhav")},children:"Udbhav Bamba ,"})}),Object(p.jsx)("h6",{className:e.float,children:Object(p.jsx)("a",{href:" ",onClick:function(){return t.push("/TransmuteAI/publications/arnav")},children:"Arnav Chavan ,"})}),Object(p.jsx)("h6",{className:e.float,children:Object(p.jsx)("a",{href:" ",onClick:function(){return t.push("/TransmuteAI/publications/deepak")},children:"Deepak K. Gupta"})})]}),Object(p.jsxs)("div",{className:e.widthup,children:[Object(p.jsx)("h5",{className:e.heading,children:Object(p.jsx)("b",{children:"Abstract"})}),Object(p.jsx)("p",{className:e.paragraph,children:"Deeper and wider CNNs are known to provide improved performance for deep learning tasks. However, most such networks have poor performance gain per parameter increase. In this paper, we investigate whether the gain observed in deeper models is purely due to the addition of more optimization parameters or whether the physical size of the network as well plays a role. Further, we present a novel rescaling strategy for CNNs based on learnable repetition of its parameters. Based on this strategy, we rescale CNNs without changing their parameter count, and show that learnable sharing of weights itself can provide significant boost in the performance of any given model without changing its parameter count. We show that small base networks when rescaled, can provide performance comparable to deeper networks with as low as 6% of optimization parameters of the deeper one. The relevance of weight sharing is further highlighted through the example of group-equivariant CNNs. We show that the significant improvements obtained with group-equivariant CNNs over the regular CNNs on classification problems are only partly due to the added equivariance property, and part of it comes from the learnable repetition of network weights. For rot-MNIST dataset, we show that up to 40% of the relative gain reported by state-of-the-art methods for rotation equivariance could actually be due to just the learnt repetition of weights."})]}),Object(p.jsxs)("div",{children:[Object(p.jsxs)("div",{className:e.column,children:[Object(p.jsx)("h6",{children:"Publication"}),Object(p.jsx)("h6",{children:"International Conference on Image Processing"})]}),Object(p.jsxs)("div",{className:e.column,children:[Object(p.jsx)("h6",{children:"Date"}),Object(p.jsx)("h6",{children:"May, 2021"})]}),Object(p.jsxs)("div",{className:e.column,children:[Object(p.jsx)("h6",{children:"Link"}),Object(p.jsxs)(W.a,{color:"primary",size:"small","aria-label":"small outlined button group",children:[Object(p.jsx)(I.a,{children:Object(p.jsx)("a",{href:"https://arxiv.org/abs/2101.05650",target:"_blank",rel:"noreferrer",className:e.link,children:"PDF"})}),Object(p.jsx)(I.a,{children:Object(p.jsx)("a",{href:"https://github.com/transmuteAI/RepeatNet/",target:"_blank",rel:"noreferrer",className:e.link,children:"Code"})})]})]})]})]})}var V=Object(m.a)((function(e){return{column:Object(f.a)({float:"none",fontFamily:"Sans-serif",color:"#002147"},e.breakpoints.up("sm"),{float:"left",padding:"1%"}),root:Object(f.a)({width:"96%",paddingTop:"1%",marginLeft:"2%",marginRight:"2%"},e.breakpoints.up("md"),{width:"76%",paddingTop:"1%",marginLeft:"12%",marginRight:"12%"}),paragraph:Object(f.a)({fontFamily:"Sans-serif",fontSize:"16px"},e.breakpoints.up("sm"),{fontSize:"18px"}),heading:{fontFamily:"Serif",color:"#002147"},link:{color:"#002147"},width:Object(f.a)({width:"100%",marginBottom:"22%"},e.breakpoints.up("sm"),{width:"90%",marginBottom:"8%"}),widthup:Object(f.a)({width:"100%",marginTop:"22%"},e.breakpoints.up("sm"),{width:"90%",marginTop:"8%"}),float:{float:"left"}}}));function G(){var e=V(),t=Object(j.f)();return Object(p.jsxs)("div",{className:e.root,children:[Object(p.jsxs)("div",{children:[Object(p.jsx)("h4",{className:e.heading,children:"Generating Annotated High-Fidelity Images containing Multiple Coherent Objects"}),Object(p.jsxs)("div",{className:e.width,children:[Object(p.jsx)("h6",{className:e.float,children:Object(p.jsx)("a",{href:" ",onClick:function(){return t.push("/TransmuteAI/publications/bryan")},children:"Bryan Cardenas ,"})}),Object(p.jsx)("h6",{className:e.float,children:Object(p.jsx)("a",{href:" ",onClick:function(){return t.push("/TransmuteAI/publications/deepanshu")},children:"Devanshu Arya ,"})}),Object(p.jsx)("h6",{className:e.float,children:Object(p.jsx)("a",{href:" ",onClick:function(){return t.push("/TransmuteAI/publications/deepak")},children:"Deepak K. Gupta"})})]}),Object(p.jsxs)("div",{className:e.widthup,children:[Object(p.jsx)("h4",{className:e.heading,children:Object(p.jsx)("b",{children:"Abstract"})}),Object(p.jsx)("p",{className:e.paragraph,children:"Recent developments related to generative models have made it possible to generate diverse high-fidelity images. In particular, layout-to-image generation models have gained significant attention due to their capability to generate realistic complex images containing distinct objects. These models are generally conditioned on either semantic layouts or textual descriptions. However, unlike natural images, providing auxiliary information can be extremely hard in domains such as biomedical imaging and remote sensing. In this work, we propose a multi-object generation framework that can synthesize images with multiple objects without explicitly requiring their contextual information during the generation process. Based on a vector-quantized variational autoencoder (VQ-VAE) backbone, our model learns to preserve spatial coherency within an image as well as semantic coherency between the objects and the background through two powerful autoregressive priors: PixelSNAIL and LayoutPixelSNAIL. While the PixelSNAIL learns the distribution of the latent encodings of the VQ-VAE, the LayoutPixelSNAIL is used to specifically learn the semantic distribution of the objects. An implicit advantage of our approach is that the generated samples are accompanied by object-level annotations. We demonstrate how coherency and fidelity are preserved with our method through experiments on the Multi-MNIST and CLEVR datasets; thereby outperforming state-of-the-art multi-object generative methods. The efficacy of our approach is demonstrated through application on medical imaging datasets, where we show that augmenting the training set with generated samples using our approach improves the performance of existing models."})]})]}),Object(p.jsxs)("div",{children:[Object(p.jsxs)("div",{className:e.column,children:[Object(p.jsx)("h6",{children:"Publication"}),Object(p.jsx)("h6",{children:"International Conference on Image Processing"})]}),Object(p.jsxs)("div",{className:e.column,children:[Object(p.jsx)("h6",{children:"Date"}),Object(p.jsx)("h6",{children:"May, 2021"})]}),Object(p.jsxs)("div",{className:e.column,children:[Object(p.jsx)("h6",{children:"Link"}),Object(p.jsxs)(W.a,{color:"primary",size:"small","aria-label":"small outlined button group",children:[Object(p.jsx)(I.a,{children:Object(p.jsx)("a",{href:"https://arxiv.org/abs/2006.12150",target:"_blank",rel:"noreferrer",className:e.link,children:"PDF"})}),Object(p.jsx)(I.a,{children:Object(p.jsx)("a",{href:"https://github.com/Cynetics/MSGNet/",target:"_blank",rel:"noreferrer",className:e.link,children:"Code"})})]})]})]})]})}var Q=Object(m.a)((function(e){return{column:Object(f.a)({float:"none",fontFamily:"Sans-serif",color:"#002147"},e.breakpoints.up("sm"),{float:"left",padding:"1%"}),root:Object(f.a)({width:"96%",paddingTop:"1%",marginLeft:"2%",marginRight:"2%"},e.breakpoints.up("md"),{width:"76%",paddingTop:"1%",marginLeft:"12%",marginRight:"12%"}),paragraph:Object(f.a)({fontFamily:"Sans-serif",fontSize:"16px"},e.breakpoints.up("sm"),{fontSize:"18px"}),heading:{fontFamily:"Serif",color:"#002147"},link:{color:"#002147"},width:Object(f.a)({width:"100%",marginBottom:"22%"},e.breakpoints.up("sm"),{width:"90%",marginBottom:"8%"}),widthup:Object(f.a)({width:"100%",marginTop:"22%"},e.breakpoints.up("sm"),{width:"90%",marginTop:"8%"}),float:{float:"left"}}}));function q(){var e=Q(),t=Object(j.f)();return Object(p.jsxs)("div",{className:e.root,children:[Object(p.jsxs)("div",{children:[Object(p.jsx)("h4",{className:e.heading,children:"ChipNet: Budget-Aware Pruning with Heaviside Continuous Approximations"}),Object(p.jsxs)("div",{className:e.width,children:[Object(p.jsx)("h6",{className:e.float,children:Object(p.jsx)("a",{href:" ",onClick:function(){return t.push("/TransmuteAI/publications/rishab")},children:"Rishabh Tiwari ,"})}),Object(p.jsx)("h6",{className:e.float,children:Object(p.jsx)("a",{href:" ",onClick:function(){return t.push("/TransmuteAI/publications/udbhav")},children:"Udbhav Bamba ,"})}),Object(p.jsx)("h6",{className:e.float,children:Object(p.jsx)("a",{href:" ",onClick:function(){return t.push("/TransmuteAI/publications/arnav")},children:"Arnav Chavan ,"})}),Object(p.jsx)("h6",{className:e.float,children:Object(p.jsx)("a",{href:" ",onClick:function(){return t.push("/TransmuteAI/publications/deepak")},children:"Deepak K. Gupta"})})]}),Object(p.jsxs)("div",{className:e.widthup,children:[Object(p.jsx)("h5",{className:e.heading,children:Object(p.jsx)("b",{children:"Abstract"})}),Object(p.jsx)("p",{className:e.paragraph,children:"Structured pruning methods are among the effective strategies for extracting small resource-efficient convolutional neural networks from their dense counterparts with minimal loss in accuracy. However, most existing methods still suffer from one or more limitations, that include 1) the need for training the dense model from scratch with pruning-related parameters embedded in the architecture, 2) requiring model-specific hyperparameter settings, 3) inability to include budget-related constraint in the training process, and 4) instability under scenarios of extreme pruning. In this paper, we present ChipNet, a deterministic pruning strategy that employs continuous Heaviside function and a novel crispness loss to identify a highly sparse network out of an existing dense network. Our choice of continuous Heaviside function is inspired by the field of design optimization, where the material distribution task is posed as a continuous optimization problem, but only discrete values (0 or 1) are practically feasible and expected as final outcomes. Our approach\u2019s flexible design facilitates its use with different choices of budget constraints while maintaining stability for very low target budgets. Experimental results show that ChipNet outperforms state-of-the-art structured pruning methods by remarkable margins of up to 16.1% in terms of accuracy. Further, we show that the masks obtained with ChipNet are transferable across datasets. For certain cases, it was observed that masks transferred from a model trained on feature-rich teacher dataset provide better performance on the student dataset than those obtained by directly pruning on the student data itself."})]})]}),Object(p.jsxs)("div",{children:[Object(p.jsxs)("div",{className:e.column,children:[Object(p.jsx)("h6",{children:"Publication"}),Object(p.jsx)("h6",{children:"International Conference on Image Processing"})]}),Object(p.jsxs)("div",{className:e.column,children:[Object(p.jsx)("h6",{children:"Date"}),Object(p.jsx)("h6",{children:"May, 2021"})]}),Object(p.jsxs)("div",{className:e.column,children:[Object(p.jsx)("h6",{children:"Link"}),Object(p.jsxs)(W.a,{color:"primary",size:"small","aria-label":"small outlined button group",children:[Object(p.jsx)(I.a,{children:Object(p.jsx)("a",{href:"https://openreview.net/forum?id=xCxXwTzx4L1",target:"_blank",rel:"noreferrer",className:e.link,children:"PDF"})}),Object(p.jsx)(I.a,{children:Object(p.jsx)("a",{href:"https://github.com/transmuteAI/ChipNet",target:"_blank",rel:"noreferrer",className:e.link,children:"Code"})})]})]})]})]})}var J=a(18),X=a.n(J),Z=a(19),Y=a.n(Z),$=a(20),ee=a.n($),te=a(14),ae=a.n(te),ne=Object(m.a)((function(e){return{column:Object(f.a)({float:"left"},e.breakpoints.up("md"),{float:"left"}),float:Object(f.a)({float:"none",width:"100%"},e.breakpoints.up("md"),{float:"left",width:"55%"}),root:{width:"100%"},heading:Object(f.a)({padding:"1%"},e.breakpoints.up("md"),{fontFamily:"Sans-Serif",color:"#002147",padding:"0%"}),heading0:Object(f.a)({padding:"1%",marginLeft:"9%"},e.breakpoints.up("md"),{fontFamily:"Sans-Serif",marginLeft:"0%",color:"#002147",padding:"0%"}),paragraph:Object(f.a)({fontFamily:"Sans-serif",width:"100%",padding:"1%",fontSize:"16px"},e.breakpoints.up("md"),{fontFamily:"Sans-serif",width:"100%",fontSize:"18px",padding:"0%"}),left:Object(f.a)({float:"none",width:"100%"},e.breakpoints.up("md"),{float:"left",width:"30%",marginLeft:"10%",paddingBottom:"18%",paddingTop:"2%"}),div:Object(f.a)({float:"none"},e.breakpoints.up("md"),{float:"left",width:"25%"}),transmute:Object(f.a)({width:"100%",color:"#002147",marginLeft:"32%"},e.breakpoints.up("md"),{width:"70%",marginLeft:"25%",color:"#002147"}),icons:Object(f.a)({width:"100%",marginLeft:"25%"},e.breakpoints.up("md"),{width:"70%",marginLeft:"18%",marginTop:"5%"}),image:Object(f.a)({width:"100%",marginLeft:"25%"},e.breakpoints.up("md"),{width:"70%",marginLeft:"18%"}),iconsColor:{color:"#002147",fontSize:"50px",padding:"1%"}}}));function ie(){var e=ne();return Object(p.jsxs)("div",{className:e.root,children:[Object(p.jsxs)("div",{className:e.left,children:[Object(p.jsxs)("div",{className:e.image,children:[Object(p.jsx)("img",{src:"./logo192.png",alt:"Deepak k. gupta"}),Object(p.jsx)("h5",{className:e.heading,children:Object(p.jsx)("b",{children:"Deepak k. Gupta"})})]}),Object(p.jsx)("h6",{className:e.heading0,children:Object(p.jsx)("b",{children:"Research Scientist and Founding Member,"})}),Object(p.jsx)("h6",{className:e.transmute,children:Object(p.jsx)("b",{children:"Transmute AI"})}),Object(p.jsxs)("div",{className:e.icons,children:[Object(p.jsx)("a",{href:"https://www.linkedin.com/in/deepak-gupta-05b48828/",alt:"LinkedIn",target:"_blank",rel:"noreferrer",children:Object(p.jsx)(X.a,{className:e.iconsColor})}),Object(p.jsx)("a",{href:"guptadeepak2806@gmail.com",target:"_blank",alt:"email address",rel:"noreferrer",children:Object(p.jsx)(Y.a,{className:e.iconsColor})}),Object(p.jsx)("a",{href:"https://github.com/dkgupta90",alt:"git hub",target:"_blank",rel:"noreferrer",children:Object(p.jsx)(ee.a,{className:e.iconsColor})})]})]}),Object(p.jsxs)("div",{className:e.div,children:[Object(p.jsx)("h5",{className:e.heading,children:"Interests"}),Object(p.jsxs)("ol",{className:e.paragraph,children:[Object(p.jsx)("li",{children:"Deep Learning"}),Object(p.jsx)("li",{children:"Computer Vision"}),Object(p.jsx)("li",{children:"AI for Computational Science & Engineering"}),Object(p.jsx)("li",{children:"AI for Medical Imaging"})]})]}),Object(p.jsxs)("div",{className:e.div,children:[Object(p.jsx)("h5",{className:e.heading,children:"Education"}),Object(p.jsxs)("ul",{className:e.paragraph,children:[Object(p.jsxs)("li",{children:[Object(p.jsx)(ae.a,{className:e.column}),"PhD in Computational Science/Applied Mathematics, 2013-17"]}),Object(p.jsx)("li",{children:"TU Delft, The Netherlands"}),Object(p.jsxs)("li",{children:[Object(p.jsx)(ae.a,{className:e.column}),"BS and MS in Geophysics, 2008-13"]}),Object(p.jsx)("li",{children:"Indian Institute of Technology, ISM Dhanbad, India"})]})]}),Object(p.jsxs)("div",{className:e.float,children:[Object(p.jsx)("h5",{className:e.heading,children:"Biography"}),Object(p.jsx)("p",{className:e.paragraph,children:"Hey there! I am currently working as a Research Scientist at Transmute AI and am involved in mentoring several students on cutting-edge AI projects. I am also working as an independent Ai consultant for Aramco Overseas Geophysical Centre in Delft, Netherlands, where my focus is on improving seismic data analysis using artificial intelligence. Earlier, I worked as a postdoctoral researcher at QUVA Lab and Informatics Institute, at University of Amsterdam (Jan 2019 - Jan 2021). My research focus lies in deep learning and computer vision, and I am particularly interested in developing efficient algorithms for object tracking and segmentation in videos. I am also involved in research projects at the intersection of physics, mathematics and machine learning focused towards applications in medical imaging and geophysics. If you would like to collaborate on exciting research problems from these domains, please drop me an email. Regarding internships or graduation projects with me, check these opportunities."})]})]})}var re=Object(m.a)((function(e){return{column:Object(f.a)({float:"left"},e.breakpoints.up("md"),{float:"left"}),float:Object(f.a)({float:"none",width:"100%"},e.breakpoints.up("md"),{float:"left",width:"55%"}),root:{width:"100%"},heading:Object(f.a)({padding:"1%"},e.breakpoints.up("md"),{fontFamily:"Sans-Serif",color:"#002147",padding:"0%"}),heading0:Object(f.a)({padding:"1%",marginLeft:"9%"},e.breakpoints.up("md"),{fontFamily:"Sans-Serif",marginLeft:"0%",color:"#002147",padding:"0%"}),paragraph:Object(f.a)({fontFamily:"Sans-serif",width:"100%",padding:"1%",fontSize:"16px"},e.breakpoints.up("md"),{fontFamily:"Sans-serif",width:"100%",fontSize:"18px",padding:"0%"}),left:Object(f.a)({float:"none",width:"100%"},e.breakpoints.up("md"),{float:"left",width:"30%",marginLeft:"10%",paddingBottom:"18%",paddingTop:"2%"}),div:Object(f.a)({float:"none"},e.breakpoints.up("md"),{float:"left",width:"25%"}),transmute:Object(f.a)({width:"100%",color:"#002147",marginLeft:"32%"},e.breakpoints.up("md"),{width:"70%",marginLeft:"25%",color:"#002147"}),icons:Object(f.a)({width:"100%",marginLeft:"25%"},e.breakpoints.up("md"),{width:"70%",marginLeft:"18%",marginTop:"5%"}),image:Object(f.a)({width:"100%",marginLeft:"25%"},e.breakpoints.up("md"),{width:"70%",marginLeft:"18%"}),iconsColor:{color:"#002147",fontSize:"50px",padding:"1%"}}}));function se(){var e=re();return Object(p.jsxs)("div",{className:e.root,children:[Object(p.jsxs)("div",{className:e.left,children:[Object(p.jsxs)("div",{className:e.image,children:[Object(p.jsx)("img",{src:"./logo192.png",alt:"Deepak k. gupta"}),Object(p.jsx)("h5",{className:e.heading,children:Object(p.jsx)("b",{children:"Arnav Chavan"})})]}),Object(p.jsx)("h6",{className:e.heading0,children:Object(p.jsx)("b",{children:"Student Researcher & Founding Member,"})}),Object(p.jsx)("h6",{className:e.transmute,children:Object(p.jsx)("b",{children:"Kaggle Competition Master"})}),Object(p.jsxs)("div",{className:e.icons,children:[Object(p.jsx)("a",{href:"https://www.linkedin.com/in/arnav0400/",alt:"LinkedIn",target:"_blank",rel:"noreferrer",children:Object(p.jsx)(X.a,{className:e.iconsColor,fontSize:"large"})}),Object(p.jsx)("a",{href:"arnavchavan04@gmail.com",target:"_blank",alt:"email address",rel:"noreferrer",children:Object(p.jsx)(Y.a,{className:e.iconsColor,fontSize:"large"})}),Object(p.jsx)("a",{href:"https://github.com/Arnav0400/",alt:"git hub",target:"_blank",rel:"noreferrer",children:Object(p.jsx)(ee.a,{className:e.iconsColor,fontSize:"large"})})]})]}),Object(p.jsxs)("div",{className:e.div,children:[Object(p.jsx)("h5",{className:e.heading,children:"Interests"}),Object(p.jsxs)("ol",{className:e.paragraph,children:[Object(p.jsx)("li",{children:"Deep Learning"}),Object(p.jsx)("li",{children:"Computer Vision"}),Object(p.jsx)("li",{children:"Efficient architecture search"})]})]}),Object(p.jsxs)("div",{className:e.div,children:[Object(p.jsx)("h5",{className:e.heading,children:"Education"}),Object(p.jsxs)("ul",{className:e.paragraph,children:[Object(p.jsxs)("li",{children:[Object(p.jsx)(ae.a,{style:{float:"left",width:"10%"}}),"Integrated Master of Technology in Mathematics and Computing, 2018-2023"]}),Object(p.jsx)("li",{children:"TU Delft, The Netherlands"}),Object(p.jsxs)("li",{children:[Object(p.jsx)(ae.a,{style:{float:"left",width:"10%"}}),"Indian Institute of Technology (ISM), Dhanbad"]})]})]}),Object(p.jsxs)("div",{className:e.float,children:[Object(p.jsx)("h5",{className:e.heading,children:"Biography"}),Object(p.jsx)("p",{className:e.paragraph,children:"I am an Integrated Masters Student in Mathematics And Computing at Indian Institute Of Technology IIT-ISM, Dhanbad, India. My primary research interest is in the field of Deep Learning and Computer Vision. I have worked on a variety of segmentation tasks invloving medical and industrial data in the past. Also, I have done some work in efficient network designing strategies through neural architecture pruning and neural architecture designing and pushed the SOTA performance for the same. I used to work on the intersection of medical imaging tasks involving X-rays and CT-scans, and deep learning.In my free time, I love to take part in kaggle competitons and explore the rapid development of deep learning in other fields. Recently, I became a Kaggle Competitions Master. When I\u2019m not involved in any coding related stuff, I love to play games and browse through development in other tech-fields"})]})]})}var ce=Object(m.a)((function(e){return{column:Object(f.a)({float:"left"},e.breakpoints.up("md"),{float:"left"}),float:Object(f.a)({float:"none",width:"100%"},e.breakpoints.up("md"),{float:"left",width:"55%"}),root:{width:"100%"},heading:Object(f.a)({padding:"1%"},e.breakpoints.up("md"),{fontFamily:"Sans-Serif",color:"#002147",padding:"0%"}),heading0:Object(f.a)({padding:"1%",marginLeft:"9%"},e.breakpoints.up("md"),{fontFamily:"Sans-Serif",marginLeft:"0%",color:"#002147",padding:"0%"}),paragraph:Object(f.a)({fontFamily:"Sans-serif",width:"100%",padding:"1%",fontSize:"16px"},e.breakpoints.up("md"),{fontFamily:"Sans-serif",width:"100%",fontSize:"18px",padding:"0%"}),left:Object(f.a)({float:"none",width:"100%"},e.breakpoints.up("md"),{float:"left",width:"30%",marginLeft:"10%",paddingBottom:"18%",paddingTop:"2%"}),div:Object(f.a)({float:"none"},e.breakpoints.up("md"),{float:"left",width:"25%"}),transmute:Object(f.a)({width:"100%",color:"#002147",marginLeft:"32%"},e.breakpoints.up("md"),{width:"70%",marginLeft:"25%",color:"#002147"}),icons:Object(f.a)({width:"100%",marginLeft:"25%"},e.breakpoints.up("md"),{width:"70%",marginLeft:"18%",marginTop:"5%"}),image:Object(f.a)({width:"100%",marginLeft:"25%"},e.breakpoints.up("md"),{width:"70%",marginLeft:"18%"}),iconsColor:{color:"#002147",fontSize:"50px",padding:"1%"}}}));function oe(){var e=ce();return Object(p.jsxs)("div",{className:e.root,children:[Object(p.jsxs)("div",{className:e.left,children:[Object(p.jsxs)("div",{className:e.image,children:[Object(p.jsx)("img",{src:"./logo192.png",alt:"Deepak k. gupta"}),Object(p.jsx)("h5",{className:e.heading,children:Object(p.jsx)("b",{children:"Rishabh Tiwari"})})]}),Object(p.jsx)("h6",{className:e.heading0,children:Object(p.jsx)("b",{children:"Student Researcher & Founding Member,"})}),Object(p.jsx)("h6",{className:e.transmute,children:Object(p.jsx)("b",{children:"Kaggle Competition Master"})}),Object(p.jsxs)("div",{className:e.icons,children:[Object(p.jsx)("a",{href:"https://www.linkedin.com/in/rishabh-tiwari16/",alt:"LinkedIn",target:"_blank",rel:"noreferrer",children:Object(p.jsx)(X.a,{className:e.iconsColor,fontSize:"large"})}),Object(p.jsx)("a",{href:"akchitra99@gmail.com",target:"_blank",alt:"email address",rel:"noreferrer",children:Object(p.jsx)(Y.a,{className:e.iconsColor,fontSize:"large"})}),Object(p.jsx)("a",{href:"https://github.com/rishabh-16/",alt:"git hub",target:"_blank",rel:"noreferrer",children:Object(p.jsx)(ee.a,{className:e.iconsColor,fontSize:"large"})})]})]}),Object(p.jsxs)("div",{className:e.div,children:[Object(p.jsx)("h5",{className:e.heading,children:"Interests"}),Object(p.jsxs)("ol",{className:e.paragraph,children:[Object(p.jsx)("li",{children:"Deep Learning"}),Object(p.jsx)("li",{children:"Computer Vision"}),Object(p.jsx)("li",{children:"Efficient architecture search"})]})]}),Object(p.jsxs)("div",{className:e.div,children:[Object(p.jsx)("h5",{className:e.heading,children:"Education"}),Object(p.jsxs)("ul",{className:e.paragraph,children:[Object(p.jsxs)("li",{children:[Object(p.jsx)(ae.a,{style:{float:"left",width:"10%"}}),"Integrated Master of Technology in Mathematics and Computing, 2018-2023"]}),Object(p.jsx)("li",{children:"TU Delft, The Netherlands"}),Object(p.jsxs)("li",{children:[Object(p.jsx)(ae.a,{style:{float:"left",width:"10%"}}),"Indian Institute of Technology (ISM), Dhanbad"]})]})]}),Object(p.jsxs)("div",{className:e.float,children:[Object(p.jsx)("h5",{className:e.heading,children:"Biography"}),Object(p.jsx)("p",{className:e.paragraph,children:"Hi, I\u2019m Rishabh Tiwari, an Undergraduate student pursuing Bachelor of Technology in Engineering Physics at IIT (ISM) Dhanbad. My interest lies in the field of Deep Learning specifically Computer Vision. I have worked on a variety of projects including classification, segmentation, detection and tracking. My recent works revolves around network architecture optimization by developing novel network pruning algorithm.I enjoy taking part in competitions on Kaggle and Codeforces to diversify my domain of knowledge. Recently I became Kaggle Competitions Master by bagging a couple of silver medals in NLP competitions and a gold medal in Defect Detection Challenge. In my free time, I enjoy watching sports, binging web series and playing chess."})]})]})}var le=Object(m.a)((function(e){return{column:Object(f.a)({float:"left"},e.breakpoints.up("md"),{float:"left"}),float:Object(f.a)({float:"none",width:"100%"},e.breakpoints.up("md"),{float:"left",width:"55%"}),root:{width:"100%"},heading:Object(f.a)({padding:"1%"},e.breakpoints.up("md"),{fontFamily:"Sans-Serif",color:"#002147",padding:"0%"}),heading0:Object(f.a)({padding:"1%",marginLeft:"9%"},e.breakpoints.up("md"),{fontFamily:"Sans-Serif",marginLeft:"0%",color:"#002147",padding:"0%"}),paragraph:Object(f.a)({fontFamily:"Sans-serif",width:"100%",padding:"1%",fontSize:"16px"},e.breakpoints.up("md"),{fontFamily:"Sans-serif",width:"100%",fontSize:"18px",padding:"0%"}),left:Object(f.a)({float:"none",width:"100%"},e.breakpoints.up("md"),{float:"left",width:"30%",marginLeft:"10%",paddingBottom:"18%",paddingTop:"2%"}),div:Object(f.a)({float:"none"},e.breakpoints.up("md"),{float:"left",width:"25%"}),transmute:Object(f.a)({width:"100%",color:"#002147",marginLeft:"32%"},e.breakpoints.up("md"),{width:"70%",marginLeft:"25%",color:"#002147"}),icons:Object(f.a)({width:"100%",marginLeft:"25%"},e.breakpoints.up("md"),{width:"70%",marginLeft:"18%",marginTop:"5%"}),image:Object(f.a)({width:"100%",marginLeft:"25%"},e.breakpoints.up("md"),{width:"70%",marginLeft:"18%"}),iconsColor:{color:"#002147",fontSize:"50px",padding:"1%"}}}));function de(){var e=le();return Object(p.jsxs)("div",{className:e.root,children:[Object(p.jsxs)("div",{className:e.left,children:[Object(p.jsxs)("div",{className:e.image,children:[Object(p.jsx)("img",{src:"./logo192.png",alt:"Deepak k. gupta"}),Object(p.jsx)("h5",{className:e.heading,children:Object(p.jsx)("b",{children:"Devanshu Arya"})})]}),Object(p.jsx)("h6",{className:e.heading0,children:Object(p.jsx)("b",{children:"Deep Learning Researcher, Transmute AI"})}),Object(p.jsxs)("div",{className:e.icons,children:[Object(p.jsx)("a",{href:"https://www.linkedin.com/in/devanshu-arya-43585246/",alt:"LinkedIn",target:"_blank",rel:"noreferrer",children:Object(p.jsx)(X.a,{fontSize:"large",className:e.iconsColor})}),Object(p.jsx)("a",{href:"devanshu18@gmail.com",target:"_blank",alt:"email address",rel:"noreferrer",children:Object(p.jsx)(Y.a,{fontSize:"large",className:e.iconsColor})}),Object(p.jsx)("a",{href:"https://github.com/devanshuarya",alt:"git hub",target:"_blank",rel:"noreferrer",children:Object(p.jsx)(ee.a,{fontSize:"large",className:e.iconsColor})})]})]}),Object(p.jsxs)("div",{className:e.div,children:[Object(p.jsx)("h5",{className:e.heading,children:Object(p.jsx)("b",{children:"Interests"})}),Object(p.jsxs)("ol",{className:e.paragraph,children:[Object(p.jsx)("li",{children:"Deep Learning"}),Object(p.jsx)("li",{children:"Computer Vision"}),Object(p.jsx)("li",{children:"Graph Representation Learning"})]})]}),Object(p.jsxs)("div",{className:e.div,children:[Object(p.jsx)("h5",{className:e.heading,children:Object(p.jsx)("b",{children:"Education"})}),Object(p.jsxs)("ul",{className:e.paragraph,children:[Object(p.jsxs)("li",{children:[Object(p.jsx)(ae.a,{className:e.column}),"PhD Artificial Intelligence, 2017-2021"]}),Object(p.jsx)("li",{children:"TU Delft, The Netherlands"})]})]}),Object(p.jsxs)("div",{className:e.float,children:[Object(p.jsx)("h5",{className:e.heading,children:Object(p.jsx)("b",{children:"Biography"})}),Object(p.jsx)("p",{className:e.paragraph,children:"Hey there! I am Devanshu Arya, a PhD candidate in the MultiX group at the University of Amsterdam. My current research focus is representation learning on graph-structured data, in particular multimodal learning using hypergraphs. I have worked on developing graph based deep learning models that are scalable to datasets with many modalities, with applications in recommedner systems, link predictions and neuroimaging. I am also part of the ASGARD project, whose aim is to develop AI powered solutions for forensic investigations that can directly contribute towards the Law Enforcement Agencies (LEAs) technological autonomy across EU.I graduated from Indian Institute of Technology, Kanpur in 2015 with a B.Tech-M.Tech dual degree in Electrical Engineering. My formal background is in speech signal processing. I worked on developing Voice Activity Detection (VAD) algorithms during my master\u2019s thesis and during my internship at NTU Singapore."})]})]})}var he=Object(m.a)((function(e){return{column:Object(f.a)({float:"left"},e.breakpoints.up("md"),{float:"left"}),float:Object(f.a)({float:"none",width:"100%"},e.breakpoints.up("md"),{float:"left",width:"55%"}),root:{width:"100%"},heading:Object(f.a)({padding:"1%"},e.breakpoints.up("md"),{fontFamily:"Sans-Serif",color:"#002147",padding:"0%"}),heading0:Object(f.a)({padding:"1%",marginLeft:"9%"},e.breakpoints.up("md"),{fontFamily:"Sans-Serif",marginLeft:"0%",color:"#002147",padding:"0%"}),paragraph:Object(f.a)({fontFamily:"Sans-serif",width:"100%",padding:"1%",fontSize:"16px"},e.breakpoints.up("md"),{fontFamily:"Sans-serif",width:"100%",fontSize:"18px",padding:"0%"}),left:Object(f.a)({float:"none",width:"100%"},e.breakpoints.up("md"),{float:"left",width:"30%",marginLeft:"10%",paddingBottom:"18%",paddingTop:"2%"}),div:Object(f.a)({float:"none"},e.breakpoints.up("md"),{float:"left",width:"25%"}),transmute:Object(f.a)({width:"100%",color:"#002147",marginLeft:"32%"},e.breakpoints.up("md"),{width:"70%",marginLeft:"25%",color:"#002147"}),icons:Object(f.a)({width:"100%",marginLeft:"25%"},e.breakpoints.up("md"),{width:"70%",marginLeft:"18%",marginTop:"5%"}),image:Object(f.a)({width:"100%",marginLeft:"25%"},e.breakpoints.up("md"),{width:"70%",marginLeft:"18%"}),iconsColor:{color:"#002147",fontSize:"50px",padding:"1%"}}}));function je(){var e=he();return Object(p.jsxs)("div",{className:e.root,children:[Object(p.jsxs)("div",{className:e.left,children:[Object(p.jsxs)("div",{className:e.image,children:[Object(p.jsx)("img",{src:"./logo192.png",alt:"Deepak k. gupta"}),Object(p.jsx)("h5",{className:e.heading,children:Object(p.jsx)("b",{children:"Udbhav Bamba"})})]}),Object(p.jsx)("h6",{className:e.heading0,children:Object(p.jsx)("b",{children:"Student Researcher & Founding Member,"})}),Object(p.jsx)("h6",{className:e.heading0,children:Object(p.jsx)("b",{children:"Kaggle Competition Master"})}),Object(p.jsxs)("div",{className:e.icons,children:[Object(p.jsx)("a",{href:"https://www.linkedin.com/in/bart-van-erp/",alt:"LinkedIn",target:"_blank",rel:"noreferrer",children:Object(p.jsx)(X.a,{fontSize:"large",className:e.iconsColor})}),Object(p.jsx)("a",{href:"ubamba98@gmail.com",target:"_blank",alt:"email address",rel:"noreferrer",children:Object(p.jsx)(Y.a,{fontSize:"large",className:e.iconsColor})}),Object(p.jsx)("a",{href:"https://github.com/bartvanerp/",alt:"git hub",target:"_blank",rel:"noreferrer",children:Object(p.jsx)(ee.a,{fontSize:"large",className:e.iconsColor})})]})]}),Object(p.jsxs)("div",{className:e.div,children:[Object(p.jsx)("h5",{className:e.heading,children:Object(p.jsx)("b",{children:"Interests"})}),Object(p.jsxs)("ol",{className:e.paragraph,children:[Object(p.jsx)("li",{children:"Deep Learning"}),Object(p.jsx)("li",{children:"Computer Vision"}),Object(p.jsx)("li",{children:"Efficient architecture search"})]})]}),Object(p.jsxs)("div",{className:e.div,children:[Object(p.jsx)("h5",{className:e.heading,children:Object(p.jsx)("b",{children:"Education"})}),Object(p.jsxs)("ul",{className:e.paragraph,children:[Object(p.jsxs)("li",{children:[Object(p.jsx)(ae.a,{className:e.column}),"Integrated Master of Technology in Mathematics and Computing, 2018-2023"]}),Object(p.jsx)("li",{children:"TU Delft, The Netherlands"}),Object(p.jsxs)("li",{children:[Object(p.jsx)(ae.a,{className:e.column}),"Indian Institute of Technology (ISM), Dhanbad"]})]})]}),Object(p.jsxs)("div",{className:e.float,children:[Object(p.jsx)("h5",{className:e.heading,children:Object(p.jsx)("b",{children:"Biography"})}),Object(p.jsx)("p",{className:e.paragraph,children:"Hey there! I\u2019m Udbhav Bamba, an understudy at IIT(ISM) Dhanbad, pursuing Integrated M. Tech in Mathematics and Computing. My interest lies in understanding and developing deep learning systems. In the course of recent years, I\u2019ve worked on diverse projects, from research endeavours to interning as an applied scientist at Amazon, India. I frequently take part in machine learning and sports programming competitions on Kaggle, codeforces, and so forth to explore recent developments and fuel knowledge exploration. When I\u2019m not brainstorming ideas or furiously coding, I enjoy gaming, watching movies and geeking about them"})]})]})}var me=Object(m.a)((function(e){return{column:Object(f.a)({float:"left"},e.breakpoints.up("md"),{float:"left"}),float:Object(f.a)({float:"none",width:"100%"},e.breakpoints.up("md"),{float:"left",width:"55%"}),root:{width:"100%"},heading:Object(f.a)({padding:"1%"},e.breakpoints.up("md"),{fontFamily:"Sans-Serif",color:"#002147",padding:"0%"}),heading0:Object(f.a)({padding:"1%",marginLeft:"9%"},e.breakpoints.up("md"),{fontFamily:"Sans-Serif",marginLeft:"0%",color:"#002147",padding:"0%"}),paragraph:Object(f.a)({fontFamily:"Sans-serif",width:"100%",padding:"1%",fontSize:"16px"},e.breakpoints.up("md"),{fontFamily:"Sans-serif",width:"100%",fontSize:"18px",padding:"0%"}),left:Object(f.a)({float:"none",width:"100%"},e.breakpoints.up("md"),{float:"left",width:"30%",marginLeft:"10%",paddingBottom:"18%",paddingTop:"2%"}),div:Object(f.a)({float:"none"},e.breakpoints.up("md"),{float:"left",width:"25%"}),transmute:Object(f.a)({width:"100%",color:"#002147",marginLeft:"32%"},e.breakpoints.up("md"),{width:"70%",marginLeft:"25%",color:"#002147"}),icons:Object(f.a)({width:"100%",marginLeft:"25%"},e.breakpoints.up("md"),{width:"70%",marginLeft:"18%",marginTop:"5%"}),image:Object(f.a)({width:"100%",marginLeft:"25%"},e.breakpoints.up("md"),{width:"70%",marginLeft:"18%"}),iconsColor:{color:"#002147",fontSize:"50px",padding:"1%"}}}));function be(){var e=me();return Object(p.jsxs)("div",{className:e.root,children:[Object(p.jsxs)("div",{className:e.left,children:[Object(p.jsxs)("div",{className:e.image,children:[Object(p.jsx)("img",{src:"./logo192.png",alt:"Deepak k. gupta"}),Object(p.jsx)("h5",{className:e.heading,children:Object(p.jsx)("b",{children:"Rishabh Tiwari"})})]}),Object(p.jsx)("h6",{className:e.heading0,children:Object(p.jsx)("b",{children:"Student Researcher & Founding Member,"})}),Object(p.jsx)("h6",{className:e.heading0,children:Object(p.jsx)("b",{children:"Kaggle Competition Master"})}),Object(p.jsxs)("div",{className:e.icons,children:[Object(p.jsx)("a",{href:"https://www.linkedin.com/in/rishabh-tiwari16/",alt:"LinkedIn",target:"_blank",rel:"noreferrer",children:Object(p.jsx)(X.a,{fontSize:"large",className:e.iconsColor})}),Object(p.jsx)("a",{href:"akchitra99@gmail.com",target:"_blank",alt:"email address",rel:"noreferrer",children:Object(p.jsx)(Y.a,{fontSize:"large",className:e.iconsColor})}),Object(p.jsx)("a",{href:"https://github.com/rishabh-16/",alt:"git hub",target:"_blank",rel:"noreferrer",children:Object(p.jsx)(ee.a,{fontSize:"large",className:e.iconsColor})})]})]}),Object(p.jsxs)("div",{className:e.div,children:[Object(p.jsx)("h5",{className:e.heading,children:Object(p.jsx)("b",{children:"Interests"})}),Object(p.jsxs)("ol",{className:e.paragraph,children:[Object(p.jsx)("li",{children:"Deep Learning"}),Object(p.jsx)("li",{children:"Computer Vision"}),Object(p.jsx)("li",{children:"Efficient architecture search"})]})]}),Object(p.jsxs)("div",{className:e.div,children:[Object(p.jsx)("h5",{className:e.heading,children:Object(p.jsx)("b",{children:"Education"})}),Object(p.jsxs)("ul",{className:e.paragraph,children:[Object(p.jsxs)("li",{children:[Object(p.jsx)(ae.a,{className:e.column}),"Integrated Master of Technology in Mathematics and Computing, 2018-2023"]}),Object(p.jsx)("li",{children:"TU Delft, The Netherlands"}),Object(p.jsxs)("li",{children:[Object(p.jsx)(ae.a,{className:e.column}),"Indian Institute of Technology (ISM), Dhanbad"]})]})]}),Object(p.jsxs)("div",{className:e.float,children:[Object(p.jsx)("h5",{className:e.heading,children:Object(p.jsx)("b",{children:"Biography"})}),Object(p.jsx)("p",{className:e.paragraph,children:"Hi, I\u2019m Rishabh Tiwari, an Undergraduate student pursuing Bachelor of Technology in Engineering Physics at IIT (ISM) Dhanbad. My interest lies in the field of Deep Learning specifically Computer Vision. I have worked on a variety of projects including classification, segmentation, detection and tracking. My recent works revolves around network architecture optimization by developing novel network pruning algorithm.I enjoy taking part in competitions on Kaggle and Codeforces to diversify my domain of knowledge. Recently I became Kaggle Competitions Master by bagging a couple of silver medals in NLP competitions and a gold medal in Defect Detection Challenge. In my free time, I enjoy watching sports, binging web series and playing chess."})]})]})}var pe=function(e){Object(l.a)(a,e);var t=Object(d.a)(a);function a(){return Object(c.a)(this,a),t.apply(this,arguments)}return Object(o.a)(a,[{key:"render",value:function(){return Object(p.jsx)("div",{children:Object(p.jsxs)(h.a,{children:[Object(p.jsx)(P,{}),Object(p.jsxs)(j.c,{children:[Object(p.jsx)(j.a,{path:"/TransmuteAI",exact:!0,component:u}),Object(p.jsx)(j.a,{path:"/TransmuteAI/joinus",component:U}),Object(p.jsx)(j.a,{path:"/TransmuteAI/publications/rishab",component:be}),Object(p.jsx)(j.a,{path:"/TransmuteAI/publications/udbhav",component:je}),Object(p.jsx)(j.a,{path:"/TransmuteAI/publications/deepanshu",component:de}),Object(p.jsx)(j.a,{path:"/TransmuteAI/publications/bryan",component:oe}),Object(p.jsx)(j.a,{path:"/TransmuteAI/publications/arnav",component:se}),Object(p.jsx)(j.a,{path:"/TransmuteAI/publications/deepak",component:ie}),Object(p.jsx)(j.a,{path:"/TransmuteAI/publications/chipnets",component:q}),Object(p.jsx)(j.a,{path:"/TransmuteAI/publications/rescaling",component:H}),Object(p.jsx)(j.a,{path:"/TransmuteAI/publications/generating",component:G}),Object(p.jsx)(j.a,{path:"/TransmuteAI/publications",component:_})]})]})})}}]),a}(n.Component),ge=function(e){e&&e instanceof Function&&a.e(3).then(a.bind(null,133)).then((function(t){var a=t.getCLS,n=t.getFID,i=t.getFCP,r=t.getLCP,s=t.getTTFB;a(e),n(e),i(e),r(e),s(e)}))};s.a.render(Object(p.jsx)(i.a.StrictMode,{children:Object(p.jsx)(pe,{})}),document.getElementById("root")),ge()}},[[89,1,2]]]);
//# sourceMappingURL=main.436bd7c9.chunk.js.map